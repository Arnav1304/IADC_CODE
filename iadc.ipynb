{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column before handling:\n",
      "Borehole           1\n",
      "Start              1\n",
      "End                1\n",
      "Time Type          2\n",
      "Phase           1010\n",
      "Code               2\n",
      "Sub code           2\n",
      "Start depth       75\n",
      "End depth         75\n",
      "Hole size          6\n",
      "section name       6\n",
      "comments           2\n",
      "dtype: int64\n",
      "Missing values in each column after handling:\n",
      "Borehole           1\n",
      "Start              1\n",
      "End                1\n",
      "Time Type          2\n",
      "Phase           1010\n",
      "Code               2\n",
      "Sub code           0\n",
      "Start depth       75\n",
      "End depth         75\n",
      "Hole size          6\n",
      "section name       6\n",
      "comments           0\n",
      "dtype: int64\n",
      "Class distribution after removing rare classes:\n",
      "Sub code\n",
      "6A         357\n",
      "5A         122\n",
      "11A         93\n",
      "2A          62\n",
      "21L         61\n",
      "22B         54\n",
      "14A         43\n",
      "13A         31\n",
      "12B         21\n",
      "12A         19\n",
      "1A          19\n",
      "15A         17\n",
      "12C         16\n",
      "21A         16\n",
      "8A          14\n",
      "8B           8\n",
      "22D          7\n",
      "21B          7\n",
      "23B          6\n",
      "9A           6\n",
      "3A           4\n",
      "22A          4\n",
      "22J          4\n",
      "21E          4\n",
      "15B          3\n",
      "18A          2\n",
      "1C           2\n",
      "UNKNOWN      2\n",
      "Name: count, dtype: int64\n",
      "0                                              missing\n",
      "1    pjsm removed lstring prepared skidded cantilev...\n",
      "2    taken sbp work job hrs recorded whead pressure...\n",
      "3    connected surface lines tested psiok bleed sec...\n",
      "4    cntd bleed tbg head pressure f zero annulus w ...\n",
      "Name: comments, dtype: object\n",
      "0    UNKNOWN\n",
      "1        11A\n",
      "2        11A\n",
      "3        11A\n",
      "4        11A\n",
      "Name: Sub code, dtype: object\n",
      "object\n",
      "object\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnav\\AppData\\Local\\Temp\\ipykernel_21336\\641497342.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['comments'].fillna('missing', inplace=True)\n",
      "C:\\Users\\arnav\\AppData\\Local\\Temp\\ipykernel_21336\\641497342.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Sub code'].fillna('UNKNOWN', inplace=True)\n",
      "c:\\Users\\arnav\\OneDrive\\Desktop\\ONGC\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7164179104477612\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         11A       1.00      0.42      0.59        19\n",
      "         12A       0.67      0.50      0.57         4\n",
      "         12B       0.50      0.25      0.33         4\n",
      "         12C       0.00      0.00      0.00         3\n",
      "         13A       0.60      0.50      0.55         6\n",
      "         14A       0.75      0.67      0.71         9\n",
      "         15A       1.00      0.33      0.50         3\n",
      "         15B       0.00      0.00      0.00         1\n",
      "          1A       1.00      1.00      1.00         4\n",
      "         21A       0.75      1.00      0.86         3\n",
      "         21B       1.00      1.00      1.00         1\n",
      "         21E       0.00      0.00      0.00         1\n",
      "         21L       1.00      0.92      0.96        12\n",
      "         22A       0.00      0.00      0.00         1\n",
      "         22B       0.60      0.27      0.38        11\n",
      "         22D       0.00      0.00      0.00         1\n",
      "         22J       0.00      0.00      0.00         1\n",
      "         23B       0.00      0.00      0.00         1\n",
      "          2A       0.79      0.92      0.85        12\n",
      "          3A       1.00      1.00      1.00         1\n",
      "          5A       0.61      0.76      0.68        25\n",
      "          6A       0.68      0.93      0.79        72\n",
      "          8A       0.67      0.67      0.67         3\n",
      "          8B       0.00      0.00      0.00         2\n",
      "          9A       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.72       201\n",
      "   macro avg       0.52      0.49      0.48       201\n",
      "weighted avg       0.70      0.72      0.68       201\n",
      "\n",
      "Model saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arnav\\OneDrive\\Desktop\\ONGC\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\arnav\\OneDrive\\Desktop\\ONGC\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\arnav\\OneDrive\\Desktop\\ONGC\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as sklearn_stopwords\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('IADC_CODE.csv')\n",
    "\n",
    "# Check for missing values in the dataframe\n",
    "print(\"Missing values in each column before handling:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Data Preprocessing\n",
    "# Fill missing values in 'comments' with a placeholder\n",
    "df['comments'].fillna('missing', inplace=True)\n",
    "\n",
    "# Ensure the 'comments' column is of string type\n",
    "df['comments'] = df['comments'].astype(str)\n",
    "\n",
    "# Handling missing values in target column 'Sub code'\n",
    "df['Sub code'].fillna('UNKNOWN', inplace=True)\n",
    "\n",
    "# Verify no more missing values in 'comments' or 'Sub code'\n",
    "print(\"Missing values in each column after handling:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Clean and preprocess text data\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Remove stopwords\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in sklearn_stopwords]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['comments'] = df['comments'].apply(preprocess_text)\n",
    "\n",
    "# Remove classes with fewer than 2 instances\n",
    "class_counts = df['Sub code'].value_counts()\n",
    "classes_to_keep = class_counts[class_counts >= 2].index\n",
    "df = df[df['Sub code'].isin(classes_to_keep)]\n",
    "\n",
    "# Verify the distribution of classes after removal\n",
    "print(\"Class distribution after removing rare classes:\")\n",
    "print(df['Sub code'].value_counts())\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = df['comments']\n",
    "y = df['Sub code']\n",
    "\n",
    "# Check for any unexpected data types or values\n",
    "print(X.head())\n",
    "print(y.head())\n",
    "print(X.dtype)\n",
    "print(y.dtype)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Feature Engineering and Model Selection in a Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2))),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'tfidf__max_df': [0.5, 0.75, 1.0],\n",
    "    'clf__n_estimators': [100, 200, 300],\n",
    "    'clf__max_depth': [10, 20, None],\n",
    "    'clf__min_samples_split': [2, 5],\n",
    "    'clf__min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV with error_score='raise' to debug\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, n_jobs=-1, verbose=2, error_score='raise')\n",
    "try:\n",
    "    grid_search.fit(X_train, y_train)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Check if grid search was successful\n",
    "if hasattr(grid_search, 'best_estimator_'):\n",
    "    # Model Evaluation\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Save the best model and vectorizer for future use\n",
    "    joblib.dump(grid_search.best_estimator_, 'iadc_code_model.pkl')\n",
    "    print(\"Model saved successfully.\")\n",
    "else:\n",
    "    print(\"Grid search failed to find a suitable model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column before handling:\n",
      "Borehole           1\n",
      "Start              1\n",
      "End                1\n",
      "Time Type          2\n",
      "Phase           1010\n",
      "Code               2\n",
      "Sub code           2\n",
      "Start depth       75\n",
      "End depth         75\n",
      "Hole size          6\n",
      "section name       6\n",
      "comments           2\n",
      "dtype: int64\n",
      "Missing values in each column after handling:\n",
      "Borehole           1\n",
      "Start              1\n",
      "End                1\n",
      "Time Type          2\n",
      "Phase           1010\n",
      "Code               2\n",
      "Sub code           0\n",
      "Start depth       75\n",
      "End depth         75\n",
      "Hole size          6\n",
      "section name       6\n",
      "comments           0\n",
      "dtype: int64\n",
      "Class distribution after removing rare classes:\n",
      "Sub code\n",
      "6A         357\n",
      "5A         122\n",
      "11A         93\n",
      "2A          62\n",
      "21L         61\n",
      "22B         54\n",
      "14A         43\n",
      "13A         31\n",
      "12B         21\n",
      "12A         19\n",
      "1A          19\n",
      "15A         17\n",
      "12C         16\n",
      "21A         16\n",
      "8A          14\n",
      "8B           8\n",
      "22D          7\n",
      "21B          7\n",
      "23B          6\n",
      "9A           6\n",
      "3A           4\n",
      "22A          4\n",
      "22J          4\n",
      "21E          4\n",
      "15B          3\n",
      "18A          2\n",
      "1C           2\n",
      "UNKNOWN      2\n",
      "Name: count, dtype: int64\n",
      "0                                              missing\n",
      "1    pjsm removed lstring prepared skidded cantilev...\n",
      "2    taken sbp work job hrs recorded whead pressure...\n",
      "3    connected surface lines tested psiok bleed sec...\n",
      "4    cntd bleed tbg head pressure f zero annulus w ...\n",
      "Name: comments, dtype: object\n",
      "0    UNKNOWN\n",
      "1        11A\n",
      "2        11A\n",
      "3        11A\n",
      "4        11A\n",
      "Name: Sub code, dtype: object\n",
      "object\n",
      "object\n",
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arnav\\OneDrive\\Desktop\\ONGC\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7164179104477612\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         11A       0.92      0.58      0.71        19\n",
      "         12A       0.50      0.50      0.50         4\n",
      "         12B       0.67      0.50      0.57         4\n",
      "         12C       0.00      0.00      0.00         3\n",
      "         13A       0.75      0.50      0.60         6\n",
      "         14A       0.80      0.44      0.57         9\n",
      "         15A       1.00      0.33      0.50         3\n",
      "         15B       0.00      0.00      0.00         1\n",
      "          1A       1.00      0.75      0.86         4\n",
      "         21A       1.00      1.00      1.00         3\n",
      "         21B       1.00      1.00      1.00         1\n",
      "         21E       0.00      0.00      0.00         1\n",
      "         21L       1.00      0.92      0.96        12\n",
      "         22A       0.00      0.00      0.00         1\n",
      "         22B       0.67      0.36      0.47        11\n",
      "         22D       0.00      0.00      0.00         1\n",
      "         22J       0.00      0.00      0.00         1\n",
      "         23B       0.00      0.00      0.00         1\n",
      "          2A       0.79      0.92      0.85        12\n",
      "          3A       1.00      1.00      1.00         1\n",
      "          5A       0.77      0.68      0.72        25\n",
      "          6A       0.65      0.92      0.76        72\n",
      "          8A       0.50      0.67      0.57         3\n",
      "          8B       1.00      0.50      0.67         2\n",
      "          9A       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.72       201\n",
      "   macro avg       0.60      0.50      0.53       201\n",
      "weighted avg       0.72      0.72      0.70       201\n",
      "\n",
      "Model saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arnav\\OneDrive\\Desktop\\ONGC\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\arnav\\OneDrive\\Desktop\\ONGC\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\arnav\\OneDrive\\Desktop\\ONGC\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as sklearn_stopwords\n",
    "import re\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('IADC_CODE.csv')\n",
    "\n",
    "# Check for missing values in the dataframe\n",
    "print(\"Missing values in each column before handling:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Data Preprocessing\n",
    "# Fill missing values in 'comments' with a placeholder\n",
    "df['comments'] = df['comments'].fillna('missing')\n",
    "\n",
    "# Ensure the 'comments' column is of string type\n",
    "df['comments'] = df['comments'].astype(str)\n",
    "\n",
    "# Handling missing values in target column 'Sub code'\n",
    "df['Sub code'] = df['Sub code'].fillna('UNKNOWN')\n",
    "\n",
    "# Verify no more missing values in 'comments' or 'Sub code'\n",
    "print(\"Missing values in each column after handling:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Clean and preprocess text data\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Remove stopwords\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in sklearn_stopwords]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['comments'] = df['comments'].apply(preprocess_text)\n",
    "\n",
    "# Remove classes with fewer than 2 instances\n",
    "class_counts = df['Sub code'].value_counts()\n",
    "classes_to_keep = class_counts[class_counts >= 2].index\n",
    "df = df[df['Sub code'].isin(classes_to_keep)]\n",
    "\n",
    "# Verify the distribution of classes after removal\n",
    "print(\"Class distribution after removing rare classes:\")\n",
    "print(df['Sub code'].value_counts())\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = df['comments']\n",
    "y = df['Sub code']\n",
    "\n",
    "# Check for any unexpected data types or values\n",
    "print(X.head())\n",
    "print(y.head())\n",
    "print(X.dtype)\n",
    "print(y.dtype)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Feature Engineering and Model Selection in a Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2))),\n",
    "    ('clf', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'tfidf__max_df': [0.5, 0.75],\n",
    "    'tfidf__min_df': [1, 2],\n",
    "    'clf__n_estimators': [100, 200],\n",
    "    'clf__learning_rate': [0.1, 0.01],\n",
    "    'clf__max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "# Use StratifiedKFold for better cross-validation\n",
    "cv = StratifiedKFold(n_splits=3)\n",
    "\n",
    "# Use GridSearchCV with error_score='raise' to debug\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=cv, n_jobs=-1, verbose=2, error_score='raise')\n",
    "\n",
    "try:\n",
    "    grid_search.fit(X_train, y_train)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Check if grid search was successful\n",
    "if hasattr(grid_search, 'best_estimator_'):\n",
    "    # Model Evaluation\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Save the best model and vectorizer for future use\n",
    "    joblib.dump(grid_search.best_estimator_, 'iadc_code_model.pkl')\n",
    "    print(\"Model saved successfully.\")\n",
    "else:\n",
    "    print(\"Grid search failed to find a suitable model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (853780538.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 12\u001b[1;36m\u001b[0m\n\u001b[1;33m    df = pd.read_csv('C:\\Users\\arnav\\OneDrive\\Desktop\\ONGC\\DPR.csv')\u001b[0m\n\u001b[1;37m                                                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Local\\Temp\\ipykernel_51892\\4183313124.py:10: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path, encoding='ISO-8859-1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Borehole                 Start                  End Time Type  Phase Code   \\\n",
      "0  SB_14P-5  24-09-2023 16:00:00  24-09-2023 18:00:00        PT    NaN  RDRP   \n",
      "1  SB_14P-5  24-09-2023 18:00:00  24-09-2023 20:30:00        PT    NaN  DAUP   \n",
      "2  SB_14P-5  24-09-2023 20:30:00  25-09-2023 02:00:00        PT    NaN  DAUP   \n",
      "3  SB_14P-5  25-09-2023 02:00:00  25-09-2023 04:00:00        PT    NaN  DAUP   \n",
      "4  SB_14P-5  25-09-2023 04:00:00  25-09-2023 06:00:00        PT    NaN  DAUP   \n",
      "\n",
      "  Sub code  Start depth  End depth  Hole size  ... Unnamed: 16374  \\\n",
      "0       1D       3170.0     3170.0        6.0  ...            NaN   \n",
      "1      14A       3170.0     3170.0        6.0  ...            NaN   \n",
      "2      14A       3170.0     3170.0        6.0  ...            NaN   \n",
      "3      14A       3170.0     3170.0        6.0  ...            NaN   \n",
      "4      11A       3170.0     3170.0        6.0  ...            NaN   \n",
      "\n",
      "  Unnamed: 16375  Unnamed: 16376  Unnamed: 16377  Unnamed: 16378  \\\n",
      "0            NaN             NaN             NaN             NaN   \n",
      "1            NaN             NaN             NaN             NaN   \n",
      "2            NaN             NaN             NaN             NaN   \n",
      "3            NaN             NaN             NaN             NaN   \n",
      "4            NaN             NaN             NaN             NaN   \n",
      "\n",
      "   Unnamed: 16379  Unnamed: 16380  Unnamed: 16381  Unnamed: 16382  \\\n",
      "0             NaN             NaN             NaN             NaN   \n",
      "1             NaN             NaN             NaN             NaN   \n",
      "2             NaN             NaN             NaN             NaN   \n",
      "3             NaN             NaN             NaN             NaN   \n",
      "4             NaN             NaN             NaN             NaN   \n",
      "\n",
      "   Unnamed: 16383  \n",
      "0             NaN  \n",
      "1             NaN  \n",
      "2             NaN  \n",
      "3             NaN  \n",
      "4             NaN  \n",
      "\n",
      "[5 rows x 16384 columns]\n",
      "Column names in the dataset: Index(['Borehole ', 'Start', 'End', 'Time Type', 'Phase', 'Code ', 'Sub code',\n",
      "       'Start depth', 'End depth', 'Hole size',\n",
      "       ...\n",
      "       'Unnamed: 16374', 'Unnamed: 16375', 'Unnamed: 16376', 'Unnamed: 16377',\n",
      "       'Unnamed: 16378', 'Unnamed: 16379', 'Unnamed: 16380', 'Unnamed: 16381',\n",
      "       'Unnamed: 16382', 'Unnamed: 16383'],\n",
      "      dtype='object', length=16384)\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KIIT\\Desktop\\AI\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "c:\\Users\\KIIT\\Desktop\\AI\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "80 fits failed out of a total of 160.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\KIIT\\Desktop\\AI\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\KIIT\\Desktop\\AI\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\KIIT\\Desktop\\AI\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\KIIT\\Desktop\\AI\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\KIIT\\Desktop\\AI\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1052: UserWarning: One or more of the test scores are non-finite: [0.41187215        nan 0.41187215        nan 0.41187215        nan\n",
      " 0.41187215        nan 0.66027397        nan 0.66027397        nan\n",
      " 0.66027397        nan 0.66027397        nan 0.78630137        nan\n",
      " 0.78630137        nan 0.78630137        nan 0.78630137        nan\n",
      " 0.79634703        nan 0.79634703        nan 0.79634703        nan\n",
      " 0.79634703        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 100, 'max_iter': 100, 'penalty': 'l2'}\n",
      "Best Cross-Validation Accuracy: 0.7963470319634702\n",
      "Test Set Accuracy: 0.8102189781021898\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         11A       0.90      0.70      0.79        27\n",
      "         12A       1.00      0.91      0.95        11\n",
      "         12B       0.50      0.67      0.57         3\n",
      "         12C       1.00      0.56      0.71         9\n",
      "         13A       0.83      1.00      0.91         5\n",
      "         14A       0.67      0.86      0.75        14\n",
      "         15A       0.67      0.40      0.50         5\n",
      "         15B       0.00      0.00      0.00         4\n",
      "         17A       0.00      0.00      0.00         1\n",
      "          1A       0.67      1.00      0.80         2\n",
      "          1B       1.00      1.00      1.00         2\n",
      "          1C       0.00      0.00      0.00         1\n",
      "          1D       0.83      0.83      0.83         6\n",
      "         21A       1.00      0.50      0.67         4\n",
      "         21B       0.00      0.00      0.00         2\n",
      "         21L       1.00      1.00      1.00        10\n",
      "         22B       0.00      0.00      0.00         2\n",
      "         22C       0.00      0.00      0.00         1\n",
      "         22G       0.00      0.00      0.00         1\n",
      "         23C       0.00      0.00      0.00         2\n",
      "          2A       0.92      1.00      0.96        12\n",
      "          3A       0.00      0.00      0.00         1\n",
      "          5A       0.85      0.78      0.81        36\n",
      "          6A       0.78      0.95      0.86       110\n",
      "          8B       0.00      0.00      0.00         1\n",
      "          9A       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.81       274\n",
      "   macro avg       0.52      0.49      0.49       274\n",
      "weighted avg       0.78      0.81      0.79       274\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KIIT\\Desktop\\AI\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\KIIT\\Desktop\\AI\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\KIIT\\Desktop\\AI\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset with the correct encoding\n",
    "file_path = r'C:\\Users\\KIIT\\Desktop\\AI\\DPR.csv'  # Use raw string to avoid unicode escape issues\n",
    "data = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Print the column names to verify them\n",
    "print(\"Column names in the dataset:\", data.columns)\n",
    "\n",
    "# Column names based on the provided structure\n",
    "comments_column = 'comments'\n",
    "iadc_code_column = 'Sub code'\n",
    "\n",
    "# Check if the columns exist in the dataset\n",
    "if comments_column not in data.columns or iadc_code_column not in data.columns:\n",
    "    raise KeyError(f\"One or both columns '{comments_column}' and '{iadc_code_column}' do not exist in the dataset\")\n",
    "\n",
    "# Preprocess the data\n",
    "# Drop rows with missing values in the columns of interest\n",
    "data = data.dropna(subset=[comments_column, iadc_code_column])\n",
    "\n",
    "# Extract the comments and IADC codes\n",
    "comments = data[comments_column].astype(str).values\n",
    "iadc_codes = data[iadc_code_column].astype(str).values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(comments, iadc_codes, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature extraction using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Define the model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Define the grid of hyperparameters\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization strength\n",
    "    'penalty': ['l2', 'none'],  # Regularization type\n",
    "    'max_iter': [100, 200, 300, 500]  # Maximum number of iterations\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(f'Best Parameters: {grid_search.best_params_}')\n",
    "print(f'Best Cross-Validation Accuracy: {grid_search.best_score_}')\n",
    "\n",
    "# Use the best model to predict on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Test Set Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
