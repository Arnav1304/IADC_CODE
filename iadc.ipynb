import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Load the dataset with the correct encoding
file_path = r'C:\Users\KIIT\Desktop\AI\DPR.csv'  # Use raw string to avoid unicode escape issues
data = pd.read_csv(file_path, encoding='ISO-8859-1')

# Display the first few rows of the dataset to understand its structure
print(data.head())

# Print the column names to verify them
print("Column names in the dataset:", data.columns)

# Column names based on the provided structure
comments_column = 'comments'
iadc_code_column = 'Sub code'

# Check if the columns exist in the dataset
if comments_column not in data.columns or iadc_code_column not in data.columns:
    raise KeyError(f"One or both columns '{comments_column}' and '{iadc_code_column}' do not exist in the dataset")

# Preprocess the data
# Drop rows with missing values in the columns of interest
data = data.dropna(subset=[comments_column, iadc_code_column])

# Extract the comments and IADC codes
comments = data[comments_column].astype(str).values
iadc_codes = data[iadc_code_column].astype(str).values

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(comments, iadc_codes, test_size=0.2, random_state=42)

# Feature extraction using TF-IDF
vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Define the model
model = LogisticRegression()

# Define the grid of hyperparameters
param_grid = {
    'C': [0.1, 1, 10, 100],  # Regularization strength
    'penalty': ['l2', 'none'],  # Regularization type
    'max_iter': [100, 200, 300, 500]  # Maximum number of iterations
}

# Use GridSearchCV to find the best hyperparameters
grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', verbose=1)
grid_search.fit(X_train_tfidf, y_train)

# Print the best parameters and the best score
print(f'Best Parameters: {grid_search.best_params_}')
print(f'Best Cross-Validation Accuracy: {grid_search.best_score_}')

# Use the best model to predict on the test set
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test_tfidf)

# Evaluate the best model
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print(f'Test Set Accuracy: {accuracy}')
print('Classification Report:')
print(report)
